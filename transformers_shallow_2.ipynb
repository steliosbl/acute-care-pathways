{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, warnings, itertools\n",
    "from pathlib import Path\n",
    "from functools import partial \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport salford_datasets.salford, salford_datasets.salford_raw, transformer_experiment.utils.embeddings, transformer_experiment.utils.finetuning, transformer_experiment.utils.shallow_classifiers, transformer_experiment.utils.plots\n",
    "%aimport acd_experiment.base_dataset, acd_experiment.salford_adapter, acd_experiment.models, acd_experiment.sci, acd_experiment.systematic_comparison\n",
    "\n",
    "from salford_datasets.salford import SalfordData, SalfordFeatures, SalfordPrettyPrint, SalfordCombinations\n",
    "from acd_experiment.salford_adapter import SalfordAdapter\n",
    "from transformer_experiment.utils.embeddings import BERTModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    DATA_DIR = Path('data/Salford')\n",
    "    CACHE_DIR = Path('data/cache')\n",
    "    IMAGE_DIR = Path('images/shallow')\n",
    "    SYSTEMATIC_COMPARISON_DIR = Path('data/systematic_comparison/')\n",
    "    RE_DERIVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 17:18:53,699 [INFO] Loading processed dataset\n"
     ]
    }
   ],
   "source": [
    "from transformer_experiment.utils.shallow_classifiers import load_salford_dataset, get_train_test_indexes\n",
    "\n",
    "SAL = load_salford_dataset(Notebook.RE_DERIVE, Notebook.DATA_DIR)\n",
    "SAL_TRAIN_IDX, SAL_TEST_IDX, SAL_TEST_UNSEEN_IDX, SAL_TEST_IS_UNSEEN = get_train_test_indexes(SAL)\n",
    "Y_TRUES = {\n",
    "    'Complete': SAL.CriticalEvent.loc[SAL_TEST_IDX],\n",
    "    'Unseen': SAL.CriticalEvent.loc[SAL_TEST_UNSEEN_IDX],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "    \n",
    "def load_tz_to_device(tz_output):\n",
    "    \"\"\" Given the direct output of the tokeniser, loads the tokens to the GPU \"\"\"\n",
    "    return dict(map(\n",
    "        lambda _: (_[0], _[1].to(Notebook.DEVICE)), tz_output.items()\n",
    "    ))\n",
    "\n",
    "def split_into_batches(Xt, batch_size):\n",
    "    \"\"\" Given a tensor/ndarray and a batch size, splits it into batches of size up to batch_size along the first dimension \"\"\"\n",
    "    return np.array_split(\n",
    "        Xt, np.ceil(len(Xt)/batch_size)\n",
    "    )\n",
    "\n",
    "def get_note_embeddings(X, model_uri=BERTModels.BioClinicalBert):\n",
    "    tz, model = AutoTokenizer.from_pretrained(model_uri), AutoModel.from_pretrained(model_uri).to(Notebook.DEVICE).eval()\n",
    "    tz_kwargs = dict(truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "    get_batch_embedding = lambda x: (\n",
    "        model(\n",
    "            **load_tz_to_device(tz(list(x), **tz_kwargs))\n",
    "        )['last_hidden_state'][:, 0, :].cpu()\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = torch.cat([\n",
    "            get_batch_embedding(_) for _ in tqdm(split_into_batches(X, 500), desc=\"Generating embeddings..\")\n",
    "        ])\n",
    "    \n",
    "    return emb\n",
    "\n",
    "def get_note_embeddings_all_BERTs(sal):\n",
    "    columns = ['AE_TriageNote', 'AE_MainDiagnosis', 'AE_PresentingComplaint']\n",
    "    avail_idx = sal[columns].notna().any(axis=1)\n",
    "    X = SalfordData(sal.loc[avail_idx]).tabular_to_text(columns).values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        result = {\n",
    "            model_name: get_note_embeddings(X, model_uri).numpy() for model_name, model_uri in BERTModels.items()\n",
    "        }\n",
    "\n",
    "    result = {\n",
    "        model_name: pd.DataFrame(\n",
    "            embeddings, index=avail_idx[avail_idx].index\n",
    "        ).reindex(index=sal.index) for model_name, embeddings in result.items()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "if Notebook.RE_DERIVE:\n",
    "    NOTE_EMBEDDINGS = get_note_embeddings_all_BERTs(SAL)\n",
    "    with open('data/cache/note_embeddings.bin', 'wb') as file:\n",
    "        pickle.dump(NOTE_EMBEDDINGS, file)\n",
    "else:\n",
    "    with open('data/cache/note_embeddings.bin', 'rb') as file:\n",
    "        NOTE_EMBEDDINGS = pickle.load(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note-Only Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acd_experiment.models import Estimator_LightGBM, Estimator_L2Regression\n",
    "\n",
    "ESTIMATORS = {_._name: _ for _ in [\n",
    "    Estimator_LightGBM,\n",
    "    Estimator_L2Regression,\n",
    "]}\n",
    "STUDY_GRID = list(itertools.product(ESTIMATORS.keys(), NOTE_EMBEDDINGS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import optuna\n",
    "from acd_experiment.systematic_comparison import get_xy, PipelineFactory\n",
    "from acd_experiment.salford_adapter import SalfordAdapter\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def run_joint_estimator(sal, embeddings, estimator_name, cv_jobs=4):\n",
    "    estimator = ESTIMATORS[estimator_name]\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        X, y = SalfordAdapter(sal).xy(\n",
    "            x=SalfordCombinations['with_services'],\n",
    "            imputation = estimator._requirements['imputation'],\n",
    "            fillna = estimator._requirements['fillna'],\n",
    "            ordinal_encoding = estimator._requirements['ordinal'],\n",
    "            onehot_encoding = estimator._requirements['onehot']\n",
    "        )\n",
    "    if estimator._requirements['fillna']:\n",
    "        embeddings = embeddings.fillna(0.0)\n",
    "    X = pd.concat((X, embeddings.add_prefix('EMBEDDING__')), axis=1)\n",
    "    X_train, X_test = SalfordAdapter(X.loc[SAL_TRAIN_IDX]), SalfordAdapter(X.loc[SAL_TEST_IDX])\n",
    "    y_train, y_test = sal.CriticalEvent.loc[SAL_TRAIN_IDX], sal.CriticalEvent.loc[SAL_TEST_IDX]\n",
    "\n",
    "    params = optuna.load_study(\n",
    "        study_name =f'{estimator_name}_None_Within-1_with_notes_and_labs', storage=f'sqlite:///{Notebook.SYSTEMATIC_COMPARISON_DIR}/{estimator_name}.db'\n",
    "    ).best_params\n",
    "\n",
    "    pipeline_factory = PipelineFactory(\n",
    "        estimator=estimator, resampler=None, X_train=X_train, y_train=y_train,\n",
    "    )\n",
    "\n",
    "    model = CalibratedClassifierCV(\n",
    "        pipeline_factory(**params), cv=cv_jobs, method=\"isotonic\", n_jobs=cv_jobs,\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_proba_unseen = y_pred_proba[SAL_TEST_IS_UNSEEN]\n",
    "\n",
    "    return y_pred_proba, y_pred_proba_unseen\n",
    "\n",
    "if Notebook.RE_DERIVE:\n",
    "    RESULTS = {}\n",
    "    for estimator_name, bert_variant in (pbar := tqdm(STUDY_GRID)):\n",
    "        pbar.set_description(f'Training {estimator_name} on {bert_variant}')\n",
    "        RESULTS[(estimator_name, bert_variant, 'only')] = run_joint_estimator(SAL, NOTE_EMBEDDINGS[bert_variant], estimator_name)\n",
    "        with open(Notebook.CACHE_DIR/'transformer_shallow_results_embonly.bin', 'wb') as file:\n",
    "            pickle.dump(RESULTS, file)\n",
    "else:\n",
    "    with open(Notebook.CACHE_DIR/'transformer_shallow_results_embonly.bin', 'rb') as file:\n",
    "        RESULTS = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training L2Regression-L2Regression on PubMedBert: 100%|██████████| 12/12 [30:55<00:00, 154.63s/it]     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def run_ensemble_estimator(sal, embeddings, estimator_tabular_name, estimator_embedding_name, cv_jobs=4):\n",
    "    estimator_tabular, estimator_embedding = (\n",
    "        ESTIMATORS[estimator_tabular_name], \n",
    "        ESTIMATORS[estimator_embedding_name]\n",
    "    )\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        X_tabular, y = SalfordAdapter(sal).xy(\n",
    "            x=SalfordCombinations['with_services'],\n",
    "            imputation = estimator_tabular._requirements['imputation'],\n",
    "            fillna = estimator_tabular._requirements['fillna'],\n",
    "            ordinal_encoding = estimator_tabular._requirements['ordinal'],\n",
    "            onehot_encoding = estimator_tabular._requirements['onehot']\n",
    "        )\n",
    "    if estimator_embedding._requirements['fillna']:\n",
    "        embeddings = embeddings.fillna(0.0)\n",
    "\n",
    "    y_train, y_test = sal.CriticalEvent.loc[SAL_TRAIN_IDX], sal.CriticalEvent.loc[SAL_TEST_IDX]\n",
    "\n",
    "    y_pred_probas, y_pred_probas_unseen = [], []\n",
    "    for estimator, X in [(estimator_tabular, X_tabular), (estimator_embedding, embeddings)]:\n",
    "        X_train, X_test = SalfordAdapter(X.loc[SAL_TRAIN_IDX]), SalfordAdapter(X.loc[SAL_TEST_IDX])\n",
    "        params = optuna.load_study(\n",
    "            study_name =f'{estimator._name}_None_Within-1_with_notes_and_labs', storage=f'sqlite:///{Notebook.SYSTEMATIC_COMPARISON_DIR}/{estimator._name}.db'\n",
    "        ).best_params\n",
    "\n",
    "        pipeline = PipelineFactory(\n",
    "            estimator=estimator, resampler=None, X_train=X_train, y_train=y_train,\n",
    "        )\n",
    "\n",
    "        model = CalibratedClassifierCV(\n",
    "            pipeline(**params), cv=cv_jobs, method=\"isotonic\", n_jobs=cv_jobs,\n",
    "        ).fit(X_train, y_train)\n",
    "\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred_probas.append(y_pred_proba)\n",
    "        y_pred_probas_unseen.append(y_pred_proba[SAL_TEST_IS_UNSEEN])\n",
    "\n",
    "    y_pred_proba = np.mean(np.array(y_pred_probas), axis=0)\n",
    "    y_pred_proba_unseen = np.mean(np.array(y_pred_probas_unseen), axis=0)\n",
    "\n",
    "    return y_pred_proba, y_pred_proba_unseen\n",
    "\n",
    "STUDY_GRID = list(itertools.product(ESTIMATORS.keys(), ESTIMATORS.keys(), NOTE_EMBEDDINGS.keys()))\n",
    "if Notebook.RE_DERIVE or True:\n",
    "    RESULTS = {}\n",
    "    for estimator_name_tab, estimator_name_emb, bert_variant in (pbar := tqdm(STUDY_GRID)):\n",
    "        pbar.set_description(f'Training {estimator_name_tab}-{estimator_name_emb} on {bert_variant}')\n",
    "        RESULTS[(estimator_name_tab, estimator_name_emb, bert_variant, 'ensemble')] = run_ensemble_estimator(SAL, NOTE_EMBEDDINGS[bert_variant], estimator_name_tab, estimator_name_emb)\n",
    "        with open(Notebook.CACHE_DIR/'transformer_shallow_results_ensemble.bin', 'wb') as file:\n",
    "            pickle.dump(RESULTS, file)\n",
    "else:\n",
    "    with open(Notebook.CACHE_DIR/'transformer_shallow_results_ensemble.bin', 'rb') as file:\n",
    "        RESULTS = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_experiment.utils.shallow_classifiers import get_discriminative_metrics\n",
    "Y_TRUES = {\n",
    "    'Complete': SAL.CriticalEvent.loc[SAL_TEST_IDX],\n",
    "    'Unseen': SAL.CriticalEvent.loc[SAL_TEST_UNSEEN_IDX],\n",
    "}\n",
    "def get_full_metrics_tables(results):\n",
    "    metrics = {\n",
    "        'Complete': [],\n",
    "        'Unseen': [],\n",
    "    }\n",
    "    for (estimator_name_tab, estimator_name_emb, feature_group_name, _), y_preds in results.items():\n",
    "        for y_pred_proba, (y_true_name, y_true) in zip(y_preds, Y_TRUES.items()):\n",
    "\n",
    "            metrics[y_true_name].append(dict(\n",
    "                Estimator_Tab = estimator_name_tab,\n",
    "                Estimator_Emb = estimator_name_emb,\n",
    "                Features = feature_group_name,\n",
    "            ) | get_discriminative_metrics(\n",
    "                y_true, y_pred_proba\n",
    "            ))\n",
    "    \n",
    "    for y_true_name, y_true in Y_TRUES.items():\n",
    "        metrics[y_true_name].append(dict(\n",
    "            Estimator='NEWS2',\n",
    "            Features='Reference'\n",
    "        ) | get_discriminative_metrics(\n",
    "            y_true, SAL.NEWS_Score_Admission.loc[y_true.index]\n",
    "        ))\n",
    "\n",
    "    return {\n",
    "        y_true_name: pd.DataFrame(metric_list) for y_true_name, metric_list in metrics.items()\n",
    "    }\n",
    "\n",
    "METRICS = get_full_metrics_tables(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUROC_Upper</th>\n",
       "      <th>AUROC_Lower</th>\n",
       "      <th>AP</th>\n",
       "      <th>AP_Upper</th>\n",
       "      <th>AP_Lower</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator_Tab</th>\n",
       "      <th>Estimator_Emb</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">L2Regression</th>\n",
       "      <th>L2Regression</th>\n",
       "      <td>0.892936</td>\n",
       "      <td>0.899386</td>\n",
       "      <td>0.884566</td>\n",
       "      <td>0.454751</td>\n",
       "      <td>0.476971</td>\n",
       "      <td>0.429238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.891827</td>\n",
       "      <td>0.898627</td>\n",
       "      <td>0.883246</td>\n",
       "      <td>0.457700</td>\n",
       "      <td>0.480329</td>\n",
       "      <td>0.431261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LightGBM</th>\n",
       "      <th>L2Regression</th>\n",
       "      <td>0.924961</td>\n",
       "      <td>0.930581</td>\n",
       "      <td>0.918546</td>\n",
       "      <td>0.552789</td>\n",
       "      <td>0.572307</td>\n",
       "      <td>0.527996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.925593</td>\n",
       "      <td>0.931310</td>\n",
       "      <td>0.919624</td>\n",
       "      <td>0.556450</td>\n",
       "      <td>0.575067</td>\n",
       "      <td>0.531869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                AUROC  AUROC_Upper  AUROC_Lower        AP  \\\n",
       "Estimator_Tab Estimator_Emb                                                 \n",
       "L2Regression  L2Regression   0.892936     0.899386     0.884566  0.454751   \n",
       "              LightGBM       0.891827     0.898627     0.883246  0.457700   \n",
       "LightGBM      L2Regression   0.924961     0.930581     0.918546  0.552789   \n",
       "              LightGBM       0.925593     0.931310     0.919624  0.556450   \n",
       "\n",
       "                             AP_Upper  AP_Lower  \n",
       "Estimator_Tab Estimator_Emb                      \n",
       "L2Regression  L2Regression   0.476971  0.429238  \n",
       "              LightGBM       0.480329  0.431261  \n",
       "LightGBM      L2Regression   0.572307  0.527996  \n",
       "              LightGBM       0.575067  0.531869  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRICS['Complete'].groupby(['Estimator_Tab', 'Estimator_Emb']).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuned transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading BioClinicalBert:41: : 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_transformer_y_preds():\n",
    "    y_preds = {}\n",
    "    for bert_variant, experiment in (pbar:= tqdm(itertools.product(BERTModels.keys(), [41, 42, 43, 45]))):\n",
    "        pbar.set_description(f'Loading {bert_variant}:{experiment}')\n",
    "        with open(f'models/bert_{bert_variant}_{experiment}/test_pred_proba_indexed.bin', 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    return y_preds\n",
    "\n",
    "TRANSFORMER_Y_PREDS = load_transformer_y_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORMER_Y_PREDS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2104865e4d02caf357b4f17570cecf3aad1d3e04a9c3efec371f5583b6707d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
