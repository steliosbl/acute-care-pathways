{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, warnings, dataclasses, itertools\n",
    "from pathlib import Path\n",
    "from functools import partial \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy import stats as st\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport salford_datasets.salford, salford_datasets.salford_raw, transformer_experiment.utils\n",
    "\n",
    "from salford_datasets.salford import SalfordData, SalfordFeatures, SalfordPrettyPrint, SalfordCombinations\n",
    "from salford_datasets.utils import DotDict\n",
    "\n",
    "from transformer_experiment.utils import dict_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    DATA_DIR = Path('data/Salford/')\n",
    "    RE_DERIVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Notebook.RE_DERIVE:\n",
    "    SAL = SalfordData.from_raw(\n",
    "        pd.read_hdf(Notebook.DATA_DIR/'raw_v2.h5', 'table')\n",
    "    ).augment_derive_all()\n",
    "    SAL.to_hdf(Notebook.DATA_DIR/'sal_processed_transformers.h5', 'table')\n",
    "else:\n",
    "    SAL = SalfordData(pd.read_hdf(Notebook.DATA_DIR/'sal_processed_transformers.h5', 'table'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTModels = DotDict(\n",
    "    BioClinicalBert=\"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    Bert=\"distilbert-base-uncased\",\n",
    "    PubMedBert=\"ml4pubmed/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext_pub_section\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments: \n",
    " 1. Tabular Data only\n",
    " 2. Note Embeddings Only\n",
    " 3. Tabular & Note Embeddings\n",
    "    - One model for both\n",
    "    - Ensemble separate models\n",
    " 4. Note Transformer\n",
    " 5. Text-ified record Transformer\n",
    " 6. Note & Text-ified record Transformer\n",
    "    - One model for both\n",
    "    - Ensemble separate models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, average_precision_score, fbeta_score, make_scorer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "CROSS_VALIDATION_METRICS = dict(\n",
    "    Precision='precision',\n",
    "    Recall='recall',\n",
    "    AUC='roc_auc',\n",
    "    AP='average_precision',\n",
    "    F1='f1',\n",
    "    F2=make_scorer(fbeta_score, beta=2)\n",
    ")\n",
    "\n",
    "LIGHTGBM_PARAMETERS = dict(\n",
    "    objective='binary',\n",
    "    random_state=123,\n",
    "    metrics=['l2', 'auc'],\n",
    "    boosting_type='gbdt',\n",
    "    is_unbalance=True,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "REGRESSION_PARAMETERS = dict(\n",
    "    max_iter=5000,\n",
    "    solver='lbfgs',\n",
    "    random_state=123,\n",
    "    penalty='l2'\n",
    ")\n",
    "\n",
    "CALIBRATION_PARAMETERS = dict(\n",
    "    ensemble=True,\n",
    "    cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=123),\n",
    "    method='isotonic',\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "CROSS_VALIDATION_PARAMETERS = dict(\n",
    "    cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=123),\n",
    "    n_jobs=1,\n",
    "    scoring=CROSS_VALIDATION_METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "REGRESSION_PREPROCESSOR = make_column_transformer(\n",
    "    (OneHotEncoder(), make_column_selector(dtype_include='category')),\n",
    "    (SimpleImputer(strategy='median'), make_column_selector(dtype_include=np.number)),\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import IsotonicRegression\n",
    "def run_shallow_CV_experiments(X_variants, y):\n",
    "    classifiers = {\n",
    "        'LightGBM': LGBMClassifier(\n",
    "            **LIGHTGBM_PARAMETERS\n",
    "        ),\n",
    "        'LR-L2': LogisticRegression(   \n",
    "            **REGRESSION_PARAMETERS\n",
    "        )\n",
    "    }\n",
    "\n",
    "    experiments = itertools.product(X_variants.items(), classifiers.items())\n",
    "\n",
    "    results = []\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for (X_name, X), (classifier_name, classifier) in (pbar := tqdm(experiments)):\n",
    "            pbar.set_description(f'Parallel running 4 CV folds of {classifier_name} with {X_name} embeddings..')\n",
    "            if classifier_name == 'LR-L2':\n",
    "                X = REGRESSION_PREPROCESSOR.fit_transform(X)\n",
    "\n",
    "            results.append(pd.DataFrame.from_dict(\n",
    "                cross_validate(\n",
    "                    CalibratedClassifierCV(classifier, **CALIBRATION_PARAMETERS),\n",
    "                    X, y, **CROSS_VALIDATION_PARAMETERS\n",
    "                )\n",
    "            ).assign(Embedding=X_name, Classifier=classifier_name))\n",
    "    \n",
    "\n",
    "    return pd.concat(results).groupby(['Embedding', 'Classifier']).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tabular Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_AP</th>\n",
       "      <th>test_F1</th>\n",
       "      <th>test_F2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding</th>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">news</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>8.647021</td>\n",
       "      <td>0.258225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594588</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>2.506067</td>\n",
       "      <td>0.990190</td>\n",
       "      <td>0.545704</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.690098</td>\n",
       "      <td>0.133228</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.004891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">with_composites</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>96.810492</td>\n",
       "      <td>0.252361</td>\n",
       "      <td>0.657983</td>\n",
       "      <td>0.051477</td>\n",
       "      <td>0.788370</td>\n",
       "      <td>0.246132</td>\n",
       "      <td>0.095479</td>\n",
       "      <td>0.063111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>5.015228</td>\n",
       "      <td>2.101757</td>\n",
       "      <td>0.677930</td>\n",
       "      <td>0.118125</td>\n",
       "      <td>0.846199</td>\n",
       "      <td>0.326153</td>\n",
       "      <td>0.201150</td>\n",
       "      <td>0.141483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">with_labs</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>730.570759</td>\n",
       "      <td>0.352537</td>\n",
       "      <td>0.567155</td>\n",
       "      <td>0.083580</td>\n",
       "      <td>0.842708</td>\n",
       "      <td>0.280948</td>\n",
       "      <td>0.145647</td>\n",
       "      <td>0.100753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>7.765831</td>\n",
       "      <td>2.990653</td>\n",
       "      <td>0.672319</td>\n",
       "      <td>0.220170</td>\n",
       "      <td>0.918216</td>\n",
       "      <td>0.466192</td>\n",
       "      <td>0.331701</td>\n",
       "      <td>0.254383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">with_phenotype</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>62.047589</td>\n",
       "      <td>0.225753</td>\n",
       "      <td>0.723203</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.680067</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>0.074742</td>\n",
       "      <td>0.048619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>4.441151</td>\n",
       "      <td>1.745080</td>\n",
       "      <td>0.697218</td>\n",
       "      <td>0.057443</td>\n",
       "      <td>0.768164</td>\n",
       "      <td>0.230990</td>\n",
       "      <td>0.106084</td>\n",
       "      <td>0.070344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">with_services</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>221.962656</td>\n",
       "      <td>0.234918</td>\n",
       "      <td>0.877467</td>\n",
       "      <td>0.364489</td>\n",
       "      <td>0.913015</td>\n",
       "      <td>0.601378</td>\n",
       "      <td>0.514847</td>\n",
       "      <td>0.412686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>8.059408</td>\n",
       "      <td>3.304551</td>\n",
       "      <td>0.839739</td>\n",
       "      <td>0.486648</td>\n",
       "      <td>0.958504</td>\n",
       "      <td>0.719494</td>\n",
       "      <td>0.616178</td>\n",
       "      <td>0.531323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fit_time  score_time  test_Precision  \\\n",
       "Embedding       Classifier                                           \n",
       "news            LR-L2         8.647021    0.258225        0.000000   \n",
       "                LightGBM      2.506067    0.990190        0.545704   \n",
       "with_composites LR-L2        96.810492    0.252361        0.657983   \n",
       "                LightGBM      5.015228    2.101757        0.677930   \n",
       "with_labs       LR-L2       730.570759    0.352537        0.567155   \n",
       "                LightGBM      7.765831    2.990653        0.672319   \n",
       "with_phenotype  LR-L2        62.047589    0.225753        0.723203   \n",
       "                LightGBM      4.441151    1.745080        0.697218   \n",
       "with_services   LR-L2       221.962656    0.234918        0.877467   \n",
       "                LightGBM      8.059408    3.304551        0.839739   \n",
       "\n",
       "                            test_Recall  test_AUC   test_AP   test_F1  \\\n",
       "Embedding       Classifier                                              \n",
       "news            LR-L2          0.000000  0.594588  0.088105  0.000000   \n",
       "                LightGBM       0.003920  0.690098  0.133228  0.007783   \n",
       "with_composites LR-L2          0.051477  0.788370  0.246132  0.095479   \n",
       "                LightGBM       0.118125  0.846199  0.326153  0.201150   \n",
       "with_labs       LR-L2          0.083580  0.842708  0.280948  0.145647   \n",
       "                LightGBM       0.220170  0.918216  0.466192  0.331701   \n",
       "with_phenotype  LR-L2          0.039432  0.680067  0.174806  0.074742   \n",
       "                LightGBM       0.057443  0.768164  0.230990  0.106084   \n",
       "with_services   LR-L2          0.364489  0.913015  0.601378  0.514847   \n",
       "                LightGBM       0.486648  0.958504  0.719494  0.616178   \n",
       "\n",
       "                             test_F2  \n",
       "Embedding       Classifier            \n",
       "news            LR-L2       0.000000  \n",
       "                LightGBM    0.004891  \n",
       "with_composites LR-L2       0.063111  \n",
       "                LightGBM    0.141483  \n",
       "with_labs       LR-L2       0.100753  \n",
       "                LightGBM    0.254383  \n",
       "with_phenotype  LR-L2       0.048619  \n",
       "                LightGBM    0.070344  \n",
       "with_services   LR-L2       0.412686  \n",
       "                LightGBM    0.531323  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def cv_tabular_classifier(sal):\n",
    "    X = SalfordData(sal[SalfordCombinations.with_services]).convert_str_to_categorical()\n",
    "    y = sal.CriticalEvent\n",
    "    X_variants = {\n",
    "        key: X[columns] for key, columns in SalfordCombinations.items()\n",
    "    }\n",
    "\n",
    "    return run_shallow_CV_experiments(X_variants, y)\n",
    "\n",
    "if Notebook.RE_DERIVE:\n",
    "    RESULTS_1 = cv_tabular_classifier(SAL)\n",
    "    RESULTS_1.to_csv('data/cache/result1.csv')\n",
    "else:\n",
    "    RESULTS_1 = pd.read_csv('data/cache/result1.csv').set_index(['Embedding', 'Classifier'])\n",
    "\n",
    "display(RESULTS_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Note Embedding Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "    \n",
    "def load_tz_to_device(tz_output):\n",
    "    \"\"\" Given the direct output of the tokeniser, loads the tokens to the GPU \"\"\"\n",
    "    return dict(map(\n",
    "        lambda _: (_[0], _[1].to(Notebook.DEVICE)), tz_output.items()\n",
    "    ))\n",
    "\n",
    "def split_into_batches(Xt, batch_size):\n",
    "    \"\"\" Given a tensor/ndarray and a batch size, splits it into batches of size up to batch_size along the first dimension \"\"\"\n",
    "    return np.array_split(\n",
    "        Xt, np.ceil(len(Xt)/batch_size)\n",
    "    )\n",
    "\n",
    "def get_note_embeddings(X, model_uri=BERTModels.BioClinicalBert):\n",
    "    tz, model = AutoTokenizer.from_pretrained(model_uri), AutoModel.from_pretrained(model_uri).to(Notebook.DEVICE).eval()\n",
    "    tz_kwargs = dict(truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "    get_batch_embedding = lambda x: (\n",
    "        model(\n",
    "            **load_tz_to_device(tz(list(x), **tz_kwargs))\n",
    "        )['last_hidden_state'][:, 0, :].cpu()\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = torch.cat([\n",
    "            get_batch_embedding(_) for _ in tqdm(split_into_batches(X, 500), desc=\"Generating embeddings..\")\n",
    "        ])\n",
    "    \n",
    "    return emb\n",
    "\n",
    "def get_note_embeddings_all_BERTs(sal):\n",
    "    columns = ['AE_TriageNote', 'AE_MainDiagnosis', 'AE_PresentingComplaint']\n",
    "    avail_idx = sal[columns].notna().any(axis=1)\n",
    "    X = SalfordData(sal.loc[avail_idx]).tabular_to_text(columns).values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        result = {\n",
    "            model_name: get_note_embeddings(X, model_uri) for model_name, model_uri in BERTModels.items()\n",
    "        }\n",
    "\n",
    "    return result, avail_idx\n",
    "\n",
    "if Notebook.RE_DERIVE:\n",
    "    NOTE_EMBEDDINGS, note_avail_idx = get_note_embeddings_all_BERTs(SAL)\n",
    "    with open('data/cache/note_embeddings.bin', 'wb') as file:\n",
    "        pickle.dump((NOTE_EMBEDDINGS, note_avail_idx), file)\n",
    "else:\n",
    "    with open('data/cache/note_embeddings.bin', 'rb') as file:\n",
    "        (NOTE_EMBEDDINGS, note_avail_idx) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_AP</th>\n",
       "      <th>test_F1</th>\n",
       "      <th>test_F2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding</th>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Bert</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>481.301529</td>\n",
       "      <td>1.944320</td>\n",
       "      <td>0.660414</td>\n",
       "      <td>0.121317</td>\n",
       "      <td>0.837179</td>\n",
       "      <td>0.328124</td>\n",
       "      <td>0.204883</td>\n",
       "      <td>0.144966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>331.267331</td>\n",
       "      <td>4.631080</td>\n",
       "      <td>0.614847</td>\n",
       "      <td>0.046985</td>\n",
       "      <td>0.825350</td>\n",
       "      <td>0.273014</td>\n",
       "      <td>0.087234</td>\n",
       "      <td>0.057619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">BioClinicalBert</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>935.784982</td>\n",
       "      <td>2.264355</td>\n",
       "      <td>0.702388</td>\n",
       "      <td>0.131871</td>\n",
       "      <td>0.847504</td>\n",
       "      <td>0.346662</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.157414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>319.884479</td>\n",
       "      <td>4.630379</td>\n",
       "      <td>0.635437</td>\n",
       "      <td>0.069744</td>\n",
       "      <td>0.839576</td>\n",
       "      <td>0.288721</td>\n",
       "      <td>0.125588</td>\n",
       "      <td>0.084831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PubMedBert</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>962.396765</td>\n",
       "      <td>4.411551</td>\n",
       "      <td>0.637574</td>\n",
       "      <td>0.143250</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>0.342452</td>\n",
       "      <td>0.233855</td>\n",
       "      <td>0.169519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>330.919344</td>\n",
       "      <td>4.579374</td>\n",
       "      <td>0.618268</td>\n",
       "      <td>0.094246</td>\n",
       "      <td>0.847822</td>\n",
       "      <td>0.308226</td>\n",
       "      <td>0.163392</td>\n",
       "      <td>0.113447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fit_time  score_time  test_Precision  \\\n",
       "Embedding       Classifier                                           \n",
       "Bert            LR-L2       481.301529    1.944320        0.660414   \n",
       "                LightGBM    331.267331    4.631080        0.614847   \n",
       "BioClinicalBert LR-L2       935.784982    2.264355        0.702388   \n",
       "                LightGBM    319.884479    4.630379        0.635437   \n",
       "PubMedBert      LR-L2       962.396765    4.411551        0.637574   \n",
       "                LightGBM    330.919344    4.579374        0.618268   \n",
       "\n",
       "                            test_Recall  test_AUC   test_AP   test_F1  \\\n",
       "Embedding       Classifier                                              \n",
       "Bert            LR-L2          0.121317  0.837179  0.328124  0.204883   \n",
       "                LightGBM       0.046985  0.825350  0.273014  0.087234   \n",
       "BioClinicalBert LR-L2          0.131871  0.847504  0.346662  0.221900   \n",
       "                LightGBM       0.069744  0.839576  0.288721  0.125588   \n",
       "PubMedBert      LR-L2          0.143250  0.851519  0.342452  0.233855   \n",
       "                LightGBM       0.094246  0.847822  0.308226  0.163392   \n",
       "\n",
       "                             test_F2  \n",
       "Embedding       Classifier            \n",
       "Bert            LR-L2       0.144966  \n",
       "                LightGBM    0.057619  \n",
       "BioClinicalBert LR-L2       0.157414  \n",
       "                LightGBM    0.084831  \n",
       "PubMedBert      LR-L2       0.169519  \n",
       "                LightGBM    0.113447  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def cv_embedding_only_classifier(sal, embeddings_dict, avail_idx):\n",
    "    y = sal.loc[avail_idx, 'CriticalEvent'].astype(int)\n",
    "    X_variants = {\n",
    "        model_name: X.numpy() for model_name, X in embeddings_dict.items()\n",
    "    }\n",
    "\n",
    "    return run_shallow_CV_experiments(X_variants, y)\n",
    "\n",
    "if Notebook.RE_DERIVE:\n",
    "    RESULTS_2 = train_embedding_only_classifier(SAL, NOTE_EMBEDDINGS, note_avail_idx)\n",
    "    RESULTS_2.to_csv('data/cache/result2.csv')\n",
    "else:\n",
    "    RESULTS_2 = pd.read_csv('data/cache/result2.csv').set_index(['Embedding', 'Classifier'])\n",
    "\n",
    "display(RESULTS_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tabular & Embedding Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 One Classifier for Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_AP</th>\n",
       "      <th>test_F1</th>\n",
       "      <th>test_F2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding</th>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Bert</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>3446.892846</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>0.865875</td>\n",
       "      <td>0.470312</td>\n",
       "      <td>0.936871</td>\n",
       "      <td>0.677538</td>\n",
       "      <td>0.609427</td>\n",
       "      <td>0.517559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>358.325441</td>\n",
       "      <td>31.259331</td>\n",
       "      <td>0.882465</td>\n",
       "      <td>0.493255</td>\n",
       "      <td>0.954317</td>\n",
       "      <td>0.720029</td>\n",
       "      <td>0.632744</td>\n",
       "      <td>0.540950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">BioClinicalBert</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>3449.244502</td>\n",
       "      <td>1.012600</td>\n",
       "      <td>0.866191</td>\n",
       "      <td>0.472424</td>\n",
       "      <td>0.939958</td>\n",
       "      <td>0.685728</td>\n",
       "      <td>0.611361</td>\n",
       "      <td>0.519660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>362.900432</td>\n",
       "      <td>31.037868</td>\n",
       "      <td>0.881836</td>\n",
       "      <td>0.493988</td>\n",
       "      <td>0.955296</td>\n",
       "      <td>0.721962</td>\n",
       "      <td>0.633221</td>\n",
       "      <td>0.541623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PubMedBert</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>3425.869108</td>\n",
       "      <td>0.895057</td>\n",
       "      <td>0.859471</td>\n",
       "      <td>0.473157</td>\n",
       "      <td>0.940401</td>\n",
       "      <td>0.685249</td>\n",
       "      <td>0.610311</td>\n",
       "      <td>0.519890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>357.951831</td>\n",
       "      <td>30.942927</td>\n",
       "      <td>0.883045</td>\n",
       "      <td>0.498577</td>\n",
       "      <td>0.955592</td>\n",
       "      <td>0.723896</td>\n",
       "      <td>0.637251</td>\n",
       "      <td>0.546107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fit_time  score_time  test_Precision  \\\n",
       "Embedding       Classifier                                            \n",
       "Bert            LR-L2       3446.892846    0.930931        0.865875   \n",
       "                LightGBM     358.325441   31.259331        0.882465   \n",
       "BioClinicalBert LR-L2       3449.244502    1.012600        0.866191   \n",
       "                LightGBM     362.900432   31.037868        0.881836   \n",
       "PubMedBert      LR-L2       3425.869108    0.895057        0.859471   \n",
       "                LightGBM     357.951831   30.942927        0.883045   \n",
       "\n",
       "                            test_Recall  test_AUC   test_AP   test_F1  \\\n",
       "Embedding       Classifier                                              \n",
       "Bert            LR-L2          0.470312  0.936871  0.677538  0.609427   \n",
       "                LightGBM       0.493255  0.954317  0.720029  0.632744   \n",
       "BioClinicalBert LR-L2          0.472424  0.939958  0.685728  0.611361   \n",
       "                LightGBM       0.493988  0.955296  0.721962  0.633221   \n",
       "PubMedBert      LR-L2          0.473157  0.940401  0.685249  0.610311   \n",
       "                LightGBM       0.498577  0.955592  0.723896  0.637251   \n",
       "\n",
       "                             test_F2  \n",
       "Embedding       Classifier            \n",
       "Bert            LR-L2       0.517559  \n",
       "                LightGBM    0.540950  \n",
       "BioClinicalBert LR-L2       0.519660  \n",
       "                LightGBM    0.541623  \n",
       "PubMedBert      LR-L2       0.519890  \n",
       "                LightGBM    0.546107  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def cv_tabular_and_embedding_classifier(sal, embeddings_dict, avail_idx):\n",
    "    X = SalfordData(sal.loc[avail_idx, SalfordCombinations.with_services]).convert_str_to_categorical()\n",
    "    y = sal.loc[avail_idx, 'CriticalEvent']\n",
    "\n",
    "    X_variants = {\n",
    "        transformer: pd.concat((X, pd.DataFrame(embedding).add_prefix('EMBEDDING_').set_index(X.index)), axis=1)\n",
    "        for transformer, embedding in embeddings_dict.items()\n",
    "    }\n",
    "\n",
    "    return run_shallow_CV_experiments(X_variants, y)\n",
    "\n",
    "if Notebook.RE_DERIVE:\n",
    "    RESULTS_31 = cv_tabular_and_embedding_classifier(SAL, NOTE_EMBEDDINGS, note_avail_idx)\n",
    "    RESULTS_31.to_csv('data/cache/result31.csv')\n",
    "else:\n",
    "    RESULTS_31 = pd.read_csv('data/cache/result31.csv').set_index(['Embedding', 'Classifier'])\n",
    "\n",
    "display(RESULTS_31)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_AP</th>\n",
       "      <th>test_F1</th>\n",
       "      <th>test_F2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding</th>\n",
       "      <th>Classifier_Data</th>\n",
       "      <th>Classifier_Emb</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Bert</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR-L2</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>750.592701</td>\n",
       "      <td>0.542523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>606.041267</td>\n",
       "      <td>0.415372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LightGBM</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>473.115724</td>\n",
       "      <td>10.148475</td>\n",
       "      <td>0.951664</td>\n",
       "      <td>0.372763</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.699402</td>\n",
       "      <td>0.535621</td>\n",
       "      <td>0.424372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>324.754093</td>\n",
       "      <td>11.136703</td>\n",
       "      <td>0.959971</td>\n",
       "      <td>0.353492</td>\n",
       "      <td>0.944035</td>\n",
       "      <td>0.697140</td>\n",
       "      <td>0.516642</td>\n",
       "      <td>0.404595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">BioClinicalBert</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR-L2</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>1329.363483</td>\n",
       "      <td>0.484679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>826.312274</td>\n",
       "      <td>0.437503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LightGBM</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>998.361817</td>\n",
       "      <td>12.950396</td>\n",
       "      <td>0.951735</td>\n",
       "      <td>0.372763</td>\n",
       "      <td>0.947542</td>\n",
       "      <td>0.704964</td>\n",
       "      <td>0.535624</td>\n",
       "      <td>0.424371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>332.994291</td>\n",
       "      <td>11.442362</td>\n",
       "      <td>0.959222</td>\n",
       "      <td>0.359640</td>\n",
       "      <td>0.945917</td>\n",
       "      <td>0.699079</td>\n",
       "      <td>0.523088</td>\n",
       "      <td>0.411008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">PubMedBert</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR-L2</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>809.081656</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>600.526571</td>\n",
       "      <td>0.408377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LightGBM</th>\n",
       "      <th>LR-L2</th>\n",
       "      <td>534.709834</td>\n",
       "      <td>11.378677</td>\n",
       "      <td>0.947544</td>\n",
       "      <td>0.375424</td>\n",
       "      <td>0.947792</td>\n",
       "      <td>0.703842</td>\n",
       "      <td>0.537694</td>\n",
       "      <td>0.426960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>321.624973</td>\n",
       "      <td>11.094053</td>\n",
       "      <td>0.955047</td>\n",
       "      <td>0.365881</td>\n",
       "      <td>0.946992</td>\n",
       "      <td>0.700792</td>\n",
       "      <td>0.528973</td>\n",
       "      <td>0.417345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   fit_time  score_time  \\\n",
       "Embedding       Classifier_Data Classifier_Emb                            \n",
       "Bert            LR-L2           LR-L2            750.592701    0.542523   \n",
       "                                LightGBM         606.041267    0.415372   \n",
       "                LightGBM        LR-L2            473.115724   10.148475   \n",
       "                                LightGBM         324.754093   11.136703   \n",
       "BioClinicalBert LR-L2           LR-L2           1329.363483    0.484679   \n",
       "                                LightGBM         826.312274    0.437503   \n",
       "                LightGBM        LR-L2            998.361817   12.950396   \n",
       "                                LightGBM         332.994291   11.442362   \n",
       "PubMedBert      LR-L2           LR-L2            809.081656    0.537361   \n",
       "                                LightGBM         600.526571    0.408377   \n",
       "                LightGBM        LR-L2            534.709834   11.378677   \n",
       "                                LightGBM         321.624973   11.094053   \n",
       "\n",
       "                                                test_Precision  test_Recall  \\\n",
       "Embedding       Classifier_Data Classifier_Emb                                \n",
       "Bert            LR-L2           LR-L2                      NaN          NaN   \n",
       "                                LightGBM                   NaN          NaN   \n",
       "                LightGBM        LR-L2                 0.951664     0.372763   \n",
       "                                LightGBM              0.959971     0.353492   \n",
       "BioClinicalBert LR-L2           LR-L2                      NaN          NaN   \n",
       "                                LightGBM                   NaN          NaN   \n",
       "                LightGBM        LR-L2                 0.951735     0.372763   \n",
       "                                LightGBM              0.959222     0.359640   \n",
       "PubMedBert      LR-L2           LR-L2                      NaN          NaN   \n",
       "                                LightGBM                   NaN          NaN   \n",
       "                LightGBM        LR-L2                 0.947544     0.375424   \n",
       "                                LightGBM              0.955047     0.365881   \n",
       "\n",
       "                                                test_AUC   test_AP   test_F1  \\\n",
       "Embedding       Classifier_Data Classifier_Emb                                 \n",
       "Bert            LR-L2           LR-L2                NaN       NaN       NaN   \n",
       "                                LightGBM             NaN       NaN       NaN   \n",
       "                LightGBM        LR-L2           0.945833  0.699402  0.535621   \n",
       "                                LightGBM        0.944035  0.697140  0.516642   \n",
       "BioClinicalBert LR-L2           LR-L2                NaN       NaN       NaN   \n",
       "                                LightGBM             NaN       NaN       NaN   \n",
       "                LightGBM        LR-L2           0.947542  0.704964  0.535624   \n",
       "                                LightGBM        0.945917  0.699079  0.523088   \n",
       "PubMedBert      LR-L2           LR-L2                NaN       NaN       NaN   \n",
       "                                LightGBM             NaN       NaN       NaN   \n",
       "                LightGBM        LR-L2           0.947792  0.703842  0.537694   \n",
       "                                LightGBM        0.946992  0.700792  0.528973   \n",
       "\n",
       "                                                 test_F2  \n",
       "Embedding       Classifier_Data Classifier_Emb            \n",
       "Bert            LR-L2           LR-L2                NaN  \n",
       "                                LightGBM             NaN  \n",
       "                LightGBM        LR-L2           0.424372  \n",
       "                                LightGBM        0.404595  \n",
       "BioClinicalBert LR-L2           LR-L2                NaN  \n",
       "                                LightGBM             NaN  \n",
       "                LightGBM        LR-L2           0.424371  \n",
       "                                LightGBM        0.411008  \n",
       "PubMedBert      LR-L2           LR-L2                NaN  \n",
       "                                LightGBM             NaN  \n",
       "                LightGBM        LR-L2           0.426960  \n",
       "                                LightGBM        0.417345  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def cv_tabular_and_embedding_ensemble(sal, embeddings_dict, avail_idx):\n",
    "    tabular_columns = SalfordCombinations.with_services\n",
    "    X = SalfordData(sal.loc[avail_idx, tabular_columns]).convert_str_to_categorical()\n",
    "    y = sal.loc[avail_idx, 'CriticalEvent']\n",
    "\n",
    "    X_variants = {\n",
    "        transformer: pd.concat((X, pd.DataFrame(embedding).add_prefix(f'EMBEDDING_').set_index(X.index)), axis=1)\n",
    "        for transformer, embedding in embeddings_dict.items()\n",
    "    }\n",
    "\n",
    "    embedding_selector = make_column_transformer(('passthrough', make_column_selector(pattern='EMBEDDING_'))).set_output(transform='pandas')\n",
    "    data_selector = make_column_transformer(('passthrough', tabular_columns)).set_output(transform='pandas')\n",
    "\n",
    "    classifier_factory = {\n",
    "        'LightGBM': lambda selector: make_pipeline(\n",
    "            selector, \n",
    "            CalibratedClassifierCV(\n",
    "                LGBMClassifier(**LIGHTGBM_PARAMETERS), **CALIBRATION_PARAMETERS\n",
    "            )),\n",
    "        'LR-L2': lambda selector: make_pipeline(\n",
    "            selector, \n",
    "            REGRESSION_PREPROCESSOR, \n",
    "            CalibratedClassifierCV(\n",
    "                LogisticRegression(**REGRESSION_PARAMETERS), **CALIBRATION_PARAMETERS\n",
    "            ))\n",
    "    }\n",
    "\n",
    "    experiments = itertools.product(\n",
    "        X_variants.items(), \n",
    "        itertools.product(classifier_factory.items(), repeat=2)\n",
    "    )\n",
    "\n",
    "    cross_validation_parameters = CROSS_VALIDATION_PARAMETERS | dict(\n",
    "        n_jobs=4\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for (X_name, X), ((cls_name_data, cls_factory_data), (cls_name_embeddings, cls_factory_embeddings)) in (pbar := tqdm(experiments)):\n",
    "            pbar.set_description(f'Parallel running 4 CV folds of {cls_name_data}-{cls_name_embeddings} with {X_name} embeddings..')\n",
    "\n",
    "            ensemble = VotingClassifier([\n",
    "                (f'DATA_{cls_name_data}', cls_factory_data(data_selector)),\n",
    "                (f'EMB_{cls_name_embeddings}', cls_factory_embeddings(embedding_selector)),\n",
    "            ], voting='soft')\n",
    "\n",
    "            results.append(pd.DataFrame.from_dict(\n",
    "                cross_validate(\n",
    "                    ensemble,\n",
    "                    X, y, **cross_validation_parameters\n",
    "                )\n",
    "            ).assign(Embedding=X_name, Classifier_Data=cls_name_data, Classifier_Emb=cls_name_embeddings))\n",
    "\n",
    "        return pd.concat(results).groupby(['Embedding', 'Classifier_Data', 'Classifier_Emb']).mean()\n",
    "\n",
    "if Notebook.RE_DERIVE:\n",
    "    RESULTS_32 = cv_tabular_and_embedding_ensemble(SAL, NOTE_EMBEDDINGS, note_avail_idx)\n",
    "    RESULTS_32.to_csv('data/cache/result32.csv')\n",
    "else:\n",
    "    RESULTS_32 = pd.read_csv('data/cache/result32.csv').set_index(['Embedding', 'Classifier_Data', 'Classifier_Emb'])\n",
    "\n",
    "display(RESULTS_32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
